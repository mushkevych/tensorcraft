{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T01:05:46.020016Z",
     "start_time": "2025-02-18T01:05:45.456334Z"
    }
   },
   "source": [
    "from os import path\n",
    "\n",
    "from compute_device import PREFERRED_DEVICE\n",
    "\n",
    "PROJECT_ROOT = path.abspath(path.join(globals()['_dh'][0], '..'))\n",
    "DATALAKE_PATH = path.abspath(path.join(PROJECT_ROOT, '..', '..', 'datalake', 'llmadapterproj'))\n",
    "FQFN_PROCESSED_DF = path.join(DATALAKE_PATH, 'processed', f'processed_20250218.jsonl')\n",
    "MODEL_DIR = path.abspath(path.join(PROJECT_ROOT, 'llmadapterproj', 'classifier'))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 17:05:46,008 - tensorcraft - INFO - XLA Device Not Supported: No module named 'torch_xla'\n",
      "2025-02-17 17:05:46,018 - tensorcraft - INFO - Pytorch version=2.6.0 preferred device=mps build with MPS support=True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T01:05:46.215268Z",
     "start_time": "2025-02-18T01:05:46.027292Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(f'file://{FQFN_PROCESSED_DF}', orient='records', lines=True)\n",
    "print(f'df shape={df.shape}')\n",
    "print(f'df columns={df.columns}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape=(704, 7)\n",
      "df columns=Index(['file_name', 'fqfn', 'text_body', 'input_ids', 'attention_mask',\n",
      "       'token_type_ids', 'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:05:48.813933Z",
     "start_time": "2025-02-18T01:05:46.289367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llmadapterproj.trainer.llmadapter_trainer import LlmAdapterTrainer, TrainerConf\n",
    "\n",
    "trainer = LlmAdapterTrainer(df, TrainerConf())"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 17:05:47,578 - tensorcraft - INFO - XLA Device Not Supported: No module named 'torch_xla'\n",
      "2025-02-17 17:05:47,579 - tensorcraft - INFO - Pytorch version=2.6.0 preferred device=mps build with MPS support=True\n",
      "2025-02-17 17:05:47,583 - tensorcraft - INFO - resolved device_name: mps compute_device: mps tensor_device: mps\n",
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-02-17 17:05:48,538 - tensorcraft - INFO - LLM Adapter model=microsoft/graphcodebert-base on mps with (#trainable_parameters, #all_parameters)=(127669211, 127669211)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(f'Training duration: {time() - start_time:.4f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-18T01:12:13.321928Z",
     "start_time": "2025-02-18T01:05:48.819012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='497' max='497' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [497/497 06:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.046459</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.992990</td>\n",
       "      <td>0.992908</td>\n",
       "      <td>0.992897</td>\n",
       "      <td>0.991071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['roberta.prompt_tuning.base_model_embeddings.weight', 'heads.default.3.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training duration: 384.5013 seconds\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:12:13.387894Z",
     "start_time": "2025-02-18T01:12:13.336243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save adapter and tokenizer\n",
    "trainer.save()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:12:13.391334Z",
     "start_time": "2025-02-18T01:12:13.390143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:12:14.895832Z",
     "start_time": "2025-02-18T01:12:13.396211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llmadapterproj.classifier.llmadapter_classifier import load_model_with_adapter\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model\n",
    "model, tokenizer = load_model_with_adapter(device_name=PREFERRED_DEVICE)\n",
    "\n",
    "# New PowerShell script to classify\n",
    "new_script = \"\"\"\n",
    "function Get-SensitiveInfo {\n",
    "    param($User)\n",
    "    Get-ADUser -Identity $User -Properties PasswordLastSet, AccountExpirationDate\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input script and move it the same device as a Model\n",
    "inputs = tokenizer(new_script, truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "inputs = {k: v.to(PREFERRED_DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Interpret results\n",
    "logits = outputs.logits\n",
    "predicted_class = torch.argmax(logits).item()\n",
    "\n",
    "label_map = {0: 'Benign', 1: 'Malicious'}\n",
    "print(f'Prediction: {label_map[predicted_class]}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaAdapterModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2025-02-17 17:12:14,334 - tensorcraft - INFO - resolved device_name: mps compute_device: mps tensor_device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Malicious\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T01:12:15.070144Z",
     "start_time": "2025-02-18T01:12:15.068666Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
