{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "\n",
    "PROJECT_ROOT = path.abspath(path.join(globals()['_dh'][0], '..'))\n",
    "DATALAKE_PATH = path.abspath(path.join(PROJECT_ROOT, '..', '..', 'datalake', 'txtproj'))\n",
    "MODEL_DIR = path.abspath(path.join(PROJECT_ROOT, 'txtproj', 'classifier'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:59:31.867528Z",
     "start_time": "2025-02-04T01:59:31.865534Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T01:59:32.041524Z",
     "start_time": "2025-02-04T01:59:31.919160Z"
    }
   },
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "FQFN_PROCESSED_DF = path.join(DATALAKE_PATH, 'processed', 'processed_20250203.jsonl')\n",
    "FQFN_VOCABULARY = path.join(DATALAKE_PATH, 'processed', 'vocabulary_20250203.json')\n",
    "\n",
    "df = pd.read_json(f'file://{FQFN_PROCESSED_DF}', orient='records', lines=True, convert_dates=False)\n",
    "\n",
    "with open(FQFN_VOCABULARY, encoding='utf-8', mode='rt') as f:\n",
    "    vocabulary = json.load(f)\n",
    "\n",
    "print(f'TextProject df shape={df.shape}')\n",
    "print(f'TextProject df columns={df.columns}')\n",
    "print(f'TextProject vocabulary size={len(vocabulary)}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextProject df shape=(410, 4)\n",
      "TextProject df columns=Index(['file_name', 'text', 'text_tfidf', 'label'], dtype='object')\n",
      "TextProject vocabulary size=256\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:59:32.048791Z",
     "start_time": "2025-02-04T01:59:32.046633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for label in df['label'].unique():\n",
    "    labeled_df = df[df['label'] == label]\n",
    "    print(f'for label {label}: {labeled_df.shape[0]} #records')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for label 0: 210 #records\n",
      "for label 1: 200 #records\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T03:14:51.963102Z",
     "start_time": "2025-02-04T03:14:51.960386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', message='.*No further splits with positive gain.*')"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T03:14:52.957332Z",
     "start_time": "2025-02-04T03:14:52.385480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trainer.txt_trainer import Trainer, TrainerConf\n",
    "from txtproj.classifier.txt_classifier import LrTxtClassifier, SvmTxtClassifier, LgbmTxtClassifier\n",
    "from txtproj.classifier.onnx_exporter import TMPL_EVAL_METRICS_FILE_NAME, TMPL_WEIGHTS_FILE_NAME\n",
    "from txtproj.classifier.txt_configuration import ModelConf\n",
    "import json\n",
    "import numpy.random\n",
    "\n",
    "for model_class in [LrTxtClassifier, SvmTxtClassifier, LgbmTxtClassifier]:\n",
    "    print(f'Detector Class: {model_class.__name__}')\n",
    "    trainer = Trainer(model_class, df, TrainerConf())\n",
    "    trainer.train()\n",
    "\n",
    "    fqfn_metrics = path.join(MODEL_DIR, TMPL_EVAL_METRICS_FILE_NAME.format(model_class.__name__))\n",
    "    metrics = trainer.evaluate(fqfn_metrics)\n",
    "    print(f'Evaluation metrics: {json.dumps(metrics, indent=2)}')\n",
    "\n",
    "    fqfn_model_save = path.join(MODEL_DIR, TMPL_WEIGHTS_FILE_NAME.format(model_class.__name__))\n",
    "    trainer.model.save_model_weights(fqfn_model_save)\n",
    "\n",
    "    model_conf = ModelConf()\n",
    "    print(f'Model input size = {model_conf.input_size}')\n",
    "\n",
    "    result = trainer.model.predict(numpy.random.random(size=(1, model_conf.input_size)))\n",
    "    print(f'Random result = {result} of type {result.dtype}')\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector Class: LrTxtClassifier\n",
      "predicted_labels.values=(array([0., 1.], dtype=float32), array([239, 171]))\n",
      "true_labels.values=(array([0, 1]), array([210, 200]))\n",
      "Evaluation metrics: {\n",
      "  \"accuracy\": 0.9049,\n",
      "  \"f1\": 0.8949,\n",
      "  \"precision\": 0.9708,\n",
      "  \"recall\": 0.83,\n",
      "  \"roc-auc\": 0.9704\n",
      "}\n",
      "Model input size = 256\n",
      "Random result = [1.] of type float32\n",
      "\n",
      "Detector Class: SvmTxtClassifier\n",
      "predicted_labels.values=(array([0., 1.], dtype=float32), array([233, 177]))\n",
      "true_labels.values=(array([0, 1]), array([210, 200]))\n",
      "Evaluation metrics: {\n",
      "  \"accuracy\": 0.9195,\n",
      "  \"f1\": 0.9125,\n",
      "  \"precision\": 0.9718,\n",
      "  \"recall\": 0.86,\n",
      "  \"roc-auc\": 0.967\n",
      "}\n",
      "Model input size = 256\n",
      "Random result = [1.] of type float32\n",
      "\n",
      "Detector Class: LgbmTxtClassifier\n",
      "[LightGBM] [Info] Number of positive: 163, number of negative: 165\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 501\n",
      "[LightGBM] [Info] Number of data points in the train set: 328, number of used features: 55\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496951 -> initscore=-0.012195\n",
      "[LightGBM] [Info] Start training from score -0.012195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "predicted_labels.values=(array([0., 1.], dtype=float32), array([238, 172]))\n",
      "true_labels.values=(array([0, 1]), array([210, 200]))\n",
      "Evaluation metrics: {\n",
      "  \"accuracy\": 0.8878,\n",
      "  \"f1\": 0.8763,\n",
      "  \"precision\": 0.9477,\n",
      "  \"recall\": 0.815,\n",
      "  \"roc-auc\": 0.9585\n",
      "}\n",
      "Model input size = 256\n",
      "Random result = [1.] of type float32\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# compute system metrics"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T03:16:37.101731Z",
     "start_time": "2025-02-04T03:16:36.764826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from trainer.np_utils import NpEncoder\n",
    "from txtproj.classifier.txt_configuration import ModelConf\n",
    "import numpy.random\n",
    "import timeit\n",
    "\n",
    "from txtproj.classifier.onnx_exporter import TMPL_WEIGHTS_FILE_NAME, TMPL_SYS_METRICS_FILE_NAME\n",
    "\n",
    "model_conf = ModelConf()\n",
    "print(f'Model input size = {model_conf.input_size}')\n",
    "\n",
    "for model_class in [LrTxtClassifier, SvmTxtClassifier, LgbmTxtClassifier]:\n",
    "    print(f'Model Class: {model_class.__name__}')\n",
    "    fqfn_model_save = path.join(MODEL_DIR, TMPL_WEIGHTS_FILE_NAME.format(model_class.__name__))\n",
    "    trained_model = model_class(model_conf=model_conf)\n",
    "    trained_model.load_model_weights(fqfn_model_save)\n",
    "\n",
    "    number_of_iterations = 1000\n",
    "    timer = timeit.Timer(stmt=lambda: trained_model.predict(numpy.random.random(size=(1, model_conf.input_size))))\n",
    "    times = timer.repeat(repeat=1, number=number_of_iterations)  # repeat=1 to run 1000 iterations once\n",
    "\n",
    "    average_time = sum(times) / (len(times) * number_of_iterations)\n",
    "\n",
    "    sys_metrics = {\n",
    "        'vocabulary_size': ModelConf.vocabulary_size,\n",
    "        'avg_inference_sec': round(average_time, 9),\n",
    "        'dataset.split_ratio': trainer.trainer_conf.dataset_split_ratio,\n",
    "    }\n",
    "    if model_class == LrTxtClassifier:\n",
    "        sys_metrics['parameter_count'] = trained_model._model.coef_.size + trained_model._model.intercept_.size\n",
    "    elif model_class == SvmTxtClassifier:\n",
    "        sys_metrics['support_vector_count'] = sum(trained_model._model.n_support_)\n",
    "    elif model_class == LgbmTxtClassifier:\n",
    "        sys_metrics['tree_count'] = trained_model._model.n_estimators_\n",
    "    else:\n",
    "        raise ValueError(f'Model class {model_class.__name__} not recognized')\n",
    "\n",
    "    for label in df['label'].unique():\n",
    "        labeled_df = df[df['label'] == label]\n",
    "        sys_metrics[f'dataset_size.class_{label}'] = labeled_df.shape[0]\n",
    "    \n",
    "    fqfn_sys_metrics = path.join(MODEL_DIR, TMPL_SYS_METRICS_FILE_NAME.format(model_class.__name__))\n",
    "    with open(fqfn_sys_metrics, 'w+') as metric_file:\n",
    "        json.dump(sys_metrics, metric_file, indent=2, cls=NpEncoder)\n",
    "    print(f'System metrics: {json.dumps(sys_metrics, indent=2, cls=NpEncoder)}')\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input size = 256\n",
      "Model Class: LrTxtClassifier\n",
      "System metrics: {\n",
      "  \"vocabulary_size\": 256,\n",
      "  \"avg_inference_sec\": 3.9255e-05,\n",
      "  \"dataset.split_ratio\": 0.2,\n",
      "  \"parameter_count\": 257,\n",
      "  \"dataset_size.class_0\": 210,\n",
      "  \"dataset_size.class_1\": 200\n",
      "}\n",
      "\n",
      "Model Class: SvmTxtClassifier\n",
      "System metrics: {\n",
      "  \"vocabulary_size\": 256,\n",
      "  \"avg_inference_sec\": 5.9557e-05,\n",
      "  \"dataset.split_ratio\": 0.2,\n",
      "  \"support_vector_count\": 161,\n",
      "  \"dataset_size.class_0\": 210,\n",
      "  \"dataset_size.class_1\": 200\n",
      "}\n",
      "\n",
      "Model Class: LgbmTxtClassifier\n",
      "System metrics: {\n",
      "  \"vocabulary_size\": 256,\n",
      "  \"avg_inference_sec\": 0.000227704,\n",
      "  \"dataset.split_ratio\": 0.2,\n",
      "  \"tree_count\": 100,\n",
      "  \"dataset_size.class_0\": 210,\n",
      "  \"dataset_size.class_1\": 200\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T01:59:33.125778Z",
     "start_time": "2024-10-07T19:52:08.641965Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
