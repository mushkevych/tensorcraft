{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:47:25.843826Z",
     "start_time": "2025-02-02T23:47:25.841312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "\n",
    "PROJECT_ROOT = path.abspath(path.join(globals()['_dh'][0], '..'))\n",
    "DATALAKE_PATH = path.abspath(path.join(PROJECT_ROOT, '..', '..', 'datalake', 'imgproj'))\n",
    "MODEL_DIR = path.abspath(path.join(PROJECT_ROOT, 'imgproj', 'classifier'))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:45:52.228876Z",
     "start_time": "2025-02-02T23:45:51.162698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from imgproj.classifier.img_configuration import ModelConf\n",
    "\n",
    "FQFN_PROCESSED_DF = path.join(DATALAKE_PATH, 'processed', f'processed_20250202.{ModelConf.image_size[0]}px.jsonl')\n",
    "\n",
    "df = pd.read_json(f'file://{FQFN_PROCESSED_DF}', orient='records', lines=True, convert_dates=False)\n",
    "original_len = df.shape[0]\n",
    "\n",
    "print(f'ImgProj df shape={df.shape}')\n",
    "print(f'ImgProj df columns={df.columns}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImgProj df shape=(502, 6)\n",
      "ImgProj df columns=Index(['file_name', 'fqfn', 'img_grey', 'img_height', 'img_width', 'label'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:45:52.299003Z",
     "start_time": "2025-02-02T23:45:52.296560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for label in df['label'].unique():\n",
    "    labeled_df = df[df['label'] == label]\n",
    "    print(f'for label {label}: {labeled_df.shape[0]} #records')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for label 0: 250 #records\n",
      "for label 1: 252 #records\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:47:29.390362Z",
     "start_time": "2025-02-02T23:47:29.336771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from imgproj.classifier.img_configuration import ModelConf\n",
    "from imgproj.classifier.img_classifier import ImgClassifier\n",
    "from imgproj.classifier.onnx_exporter import TMPL_WEIGHTS_FILE_NAME\n",
    "\n",
    "run_id = f'{datetime.now():%Y-%m-%dT%H-%M}'\n",
    "\n",
    "print(f'Model Class: {ImgClassifier.__name__}')\n",
    "model_conf = ModelConf()\n",
    "fqfn_model_save = path.join(MODEL_DIR, TMPL_WEIGHTS_FILE_NAME.format(ImgClassifier.__name__, ModelConf.image_size[0]))\n",
    "trained_model = ImgClassifier(model_conf=model_conf)\n",
    "trained_model.load_model_weights(fqfn_model_save)\n",
    "\n",
    "print(f'Model {trained_model.__class__.__name__} number of parameters = {trained_model.parameter_count:,}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Class: ImgClassifier\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Model ImgClassifier number of parameters = 4,008,253\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:47:50.104483Z",
     "start_time": "2025-02-02T23:47:34.273299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import traceback\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from trainer.grad_cam import GradCAM, instantiate_gram_cam, write_cam_to_tensorboard\n",
    "\n",
    "grad_cam: GradCAM = instantiate_gram_cam(trained_model.model)\n",
    "\n",
    "sample_size: int = 50\n",
    "with SummaryWriter(log_dir=f'tensorboard.run/grad_cam_{run_id}', comment='gradient class activation maps') as writer:\n",
    "    for label in df['label'].unique():\n",
    "        df_sub = df[df['label'] == label].sample(n=sample_size)\n",
    "        df_sub.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        for idx, row in df_sub.iterrows():\n",
    "            img_grey = row['img_grey']  # Extract the grayscale image (ndarray)\n",
    "            label = row['label']        # Extract the label (0 or 1)\n",
    "        \n",
    "            # Convert the grayscale image to a tensor with the shape [1, img_size, img_size]\n",
    "            img_tensor = torch.tensor(img_grey, dtype=torch.float32).unsqueeze(0)  # Unsqueeze to add channel dimension [1, H, W]\n",
    "\n",
    "            try:\n",
    "                write_cam_to_tensorboard(writer, grad_cam, img_tensor, label, idx)\n",
    "            except Exception as e:\n",
    "                traceback.print_exc(limit=10)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
